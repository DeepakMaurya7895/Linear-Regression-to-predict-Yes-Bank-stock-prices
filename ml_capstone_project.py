# -*- coding: utf-8 -*-
"""ML_Capstone_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X-7C2JBQiJUpOmGYxIDXWrMWdZJaevIW

![image.png](data:image/png;base64,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)

# **Project Name**    - Regression - Yes Bank Stock Closing Price Prediction

##### **Project Type**    - Regression
##### **Contribution**    - Individual

# **Project Summary -**

In this project, I applied Linear Regression to predict Yes Bank stock prices using historical OHLC (Open, High, Low, Close) data.

Key Steps:

##Data Preprocessing:

The OHLC data was initially skewed, so I applied a log transformation to both the features and the target variable to normalize the distribution.
After log transformation, I scaled the features to ensure consistent scaling across variables, preparing them for dimensionality reduction.


##Dimensionality Reduction (PCA):

Due to multicollinearity in OHLC data, I used Principal Component Analysis (PCA) to reduce dimensionality. This allowed the model to focus on the key components explaining most of the variance without overfitting.


##Train-Test Split:

The data was split into training and testing sets with an 80-20 ratio, ensuring that the target and feature indices were aligned correctly for consistent predictions.


##Model Training:

A Linear Regression model was trained on the PCA-transformed features and the log-transformed target variable (stock price). The simplicity of Linear Regression was chosen as a starting point for this analysis.


##Model Evaluation:

After training, the model's predictions were transformed back using the inverse log transformation (np.exp()), bringing both predicted and actual values back to their original scale.
The model was evaluated using key regression metrics:
Mean Squared Error (MSE).
Root Mean Squared Error (RMSE).
R² Score (Coefficient of Determination).
These metrics provided insight into how well the model predicted stock prices.


##Visualization:

I visualized the Actual vs Predicted stock prices over time using a line plot sorted by Date. This comparison highlighted the model's performance in capturing stock price trends.
Conclusion:
While the Linear Regression model demonstrated a reasonable fit, stock price prediction remains complex due to external market factors. Further improvements can be achieved by incorporating additional technical indicators or using more advanced models such as time series forecasting.

# **GitHub Link -**

# **Problem Statement**

The objective of this project is to develop a predictive model for Yes Bank stock prices using historical OHLC (Open, High, Low, Close) data.

# **General Guidelines** : -

1.   Well-structured, formatted, and commented code is required.
2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.
     
     The additional credits will have advantages over other students during Star Student selection.
       
             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go
                       without a single error logged. ]

3.   Each and every logic should have proper comments.
4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.
        

```
# Chart visualization code
```
            

*   Why did you pick the specific chart?
*   What is/are the insight(s) found from the chart?
* Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

5. You have to create at least 15 logical & meaningful charts having important insights.


[ Hints : - Do the Vizualization in  a structured way while following "UBM" Rule.

U - Univariate Analysis,

B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)

M - Multivariate Analysis
 ]





6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.


*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.


*   Cross- Validation & Hyperparameter Tuning

*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.

*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.
"""

!pip install plotly

"""# ***Let's Begin !***

## ***1. Know Your Data***

### Import Libraries
"""

#importing librabries and modules

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV

"""### Dataset Loading"""

# Load Dataset
df = pd.read_csv('/content/data_YesBank_StockPrices.csv')

"""### Dataset First View"""

df

"""### Dataset Rows & Columns count"""

df.shape

"""#### Duplicate Values"""

# Dataset Duplicate Value Count
df.duplicated().sum()

"""#### Missing Values/Null Values"""

df.isnull().sum()

# Missing Values/Null Values Count

# Visualizing the missing values using heatmap
Heatmap = sns.heatmap(df.isnull(), cbar=False)

"""mising value not available

## ***2. Understanding Your Variables***
"""

#information about columns and their datatypes
df.info()

#converting datatype of Date column from object to Date
df['Date'] = pd.to_datetime(df['Date'],format='%b-%y')

df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month

"""### Variables Description"""

# Dataset Describe
df.describe(include=[np.number])

"""Variables Description

Date : month date of record.

Open : Opening price.

High : Highest price in the month.

Low : Lowest price in the month.

Close : Closing price.

### Check Unique Values for each variable.
"""

# Check Unique Values for each variable.
df.nunique()

"""## 3. ***Data Wrangling***

### Data Wrangling Code
"""

# Create moving average features (e.g., 3-month, 6-month)
df['ma_3'] = df['Close'].rolling(window=3).mean()  # 3-month moving average
df['ma_6'] = df['Close'].rolling(window=6).mean()  # 6-month moving average

"""Lets check for outliers prsent if any

"""

fig = plt.figure(figsize=(12,6))

columns = ['Open', 'High', 'Low', 'Close']


#using subplots and for loop to print boxplot for 'OHLC' Distributions
for i, column in enumerate(columns):
    plt.subplot(2, 2, i+1)
    sns.boxplot(x=df[column])

plt.subplots_adjust(hspace=0.5)

"""seems like there  are some outliers present in each column

lets see what are the outliers
"""

#defining function to figure out outliers and print them
def show_outliers_IQR(df):
   q1=df.quantile(0.25)
   q3=df.quantile(0.75)
   IQR=q3-q1
   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]
   return outliers

#finding all outliers and putting them all in one dataframe0
outliers_df = pd.concat([show_outliers_IQR(df['Open']),
                         show_outliers_IQR(df['High']),
                         show_outliers_IQR(df['Low']),
                         show_outliers_IQR(df['Close'])],axis=1)
outliers_df.sort_index()

print('{} to {} are outliers'.format(df['Date'][144].date() ,df['Date'][159].date()))

"""The outliers detected in the dataset occur between July 2017 and September 2018, showing particularly high stock prices for Yes Bank. These are the most extreme values compared to the general range of the dataset

checked the outliers values and deduced that values present shown as outliers are nothing but volatility of market and seen values are actual stock prices

From all the above points we can say that these are not outliers , these are possible values.

---

### What all manipulations have you done and insights you found?
"""

df.info()

"""Changed date datatype from object to datetime

separated each month and year by creating two new columns

checked the outliers values and deduced that values present shown as outliers are nothing but volatility of market and seen values are actual stock prices

Potential outliers research showed that

YES Bank encountered difficulties following the central bank's asset quality reviews in 2017 and 2018, which resulted in a sharp increase in its impaired loans ratio and the discovery of significant governance lapses, resulting in a complete change of management.

## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***
"""

# Chart - 1 visualization code
fig = go.Figure(data=[go.Candlestick(x=df['Date'], open=df['Open'],high=df['High'],low=df['Low'], close=df['Close'])])

# Add title and labels
fig.update_layout(
    title='Candlestick Chart',
    yaxis_title='Price',
    xaxis_title='Date',
    xaxis_rangeslider_visible=False  # Remove range slider
)

# Show the figure
fig.show()

"""##### 1. Why did you pick the specific chart?

Candlestick charts are widely used for visualizing stock prices because they provide a rich amount of information in a compact format, allowing traders and analysts to understand market movements quickly. Here's why candlestick charts are preferred for visualizing stock prices:

Comprehensive Information:
A candlestick captures four key data points:

Open: The price at the start of the trading period.

Close: The price at the end of the trading period.

High: The highest price reached during the period.

Low: The lowest price reached during the period.

This allows traders to quickly grasp the range of price movements for a given time frame (day, week, etc.)

##### 2. What is/are the insight(s) found from the chart?

Bullish Trend with High Volatility (July 2017 - August 2018):
Rising Prices: The candlestick chart during this period likely shows a steady upward trend, with the stock price climbing from approximately ₹290 in July 2017 to a peak of ₹370+ in August 2018. This suggests a strong bullish sentiment in the market, with consistent demand for Yes Bank stock.

Volatility: Long candlestick wicks during this period would indicate high volatility. The stock prices fluctuated significantly, especially in the later months. This might signal investor uncertainty, or heightened interest due to significant market events or news related to the bank.

Potential Reversal Signals (September 2018):
Sharp Drop in Low Price: In September 2018, a significant drop in the low price (down to ₹166.15) is noticeable. If the candlestick for this month shows a long lower wick (indicating that the price dropped sharply but recovered before the close), this could signal a "hammer" pattern. A hammer often indicates a potential reversal after a downtrend, showing that buyers are starting to step in after a large sell-off.

---

Lets Visualise  min , max and mean for each of the column Year-wise
"""

Agg_df = df.groupby('Year').agg({
    'Open': ['min', 'max', 'mean'],
    'High': ['min', 'max', 'mean'],
    'Low': ['min', 'max', 'mean'],
    'Close': ['min', 'max', 'mean']
})

plt.figure(figsize = (12,8))
sns.heatmap(Agg_df , annot = True, cmap = 'coolwarm', fmt='.2f')
plt.xlabel('Min-Max-Mean')

"""Heatmap is used here to show prizes because

due to its ability to present complex data patterns in an intuitive and visually striking format.

A sudden color change in a heatmap can indicate a price spike or crash, helping analysts spot significant events or unusual activity in the stock market.

All time high was 404, it was in 2018.

All time low was 5.55, it was in 2020.

In year of 2017 and 2018 prices were at their peak.

Here also we can see price drop after 2018.
"""

# Create a histogram showing kde curve

columns = ['Open', 'High', 'Low', 'Close']

fig , ax = plt.subplots(2 , 2 ,figsize=(10, 6))


ax = ax.flatten()

for i, column in enumerate(columns):
    sns.histplot(df[column], kde=True, ax=ax[i],)  # Plot each dataset on the respective axis
    ax[i].axvline(np.mean(df[column]),color='r', linestyle='--')
    ax[i].axvline(np.median(df[column]),color='b', linestyle='--')
    ax[i].set_title(f'Plot {i+1}')  # Add a title to each subplot

plt.subplots_adjust(hspace=0.5)

"""##### 1. Why did you pick the specific chart?

A histplot (histogram plot) is a type of plot in data visualization that displays the distribution of a dataset. It’s one of the most common ways to summarize and visualize the underlying frequency distribution of continuous data.

##### 2. What is/are the insight(s) found from the chart?

histplot can show if the data is skewed to the left or right. This is important when you are trying to assess the symmetry of your data, which can affect statistical analysis and modeling.

Benefit: You can visually assess the mean, median, and mode of the data, along with how tightly or widely distributed the data points are.

Linear regression models typically assume that the residuals (errors) are normally distributed. When the data is skewed, this assumption is violated.

Impact: Skewed data can result in residuals that are also skewed, leading to unreliable hypothesis tests, inaccurate confidence intervals, and incorrect p-values for determining variable significance.

---

Lets visualize 'open' , 'close' relationship using Scatter plot

Choosing a scatterplot to visualize the relationship between the Open and Close prices of stock data offers several benefits:

**Correlation Detection**: Scatterplots help in visualizing how the Open and Close prices are related. A linear or clustered pattern in the plot can indicate the strength and direction of their relationship (positive, negative, or no correlation).


**Trend Identification**: If the scatterplot shows a strong linear pattern, it might suggest that stock prices tend to close near their opening prices. Conversely, deviations can highlight volatile days.


**Outlier Detection**: Scatterplots make it easy to spot days when the Close price significantly deviates from the Open price, indicating abnormal price movements or high volatility.


**Simple and Intuitive**: A scatterplot is a simple yet effective way to represent the data points without clutter, making it easy to interpret.
"""



#scatter plot between open and close columns

plt.scatter(df['Open'], df['Close'])
corr = df['Open'].corr(df['Close'])
plt.title(f'Scatter Plot of Open vs Close (Correlation: {corr:4f})')
plt.xlabel('Open')
plt.ylabel('Close')

#scatter plot between high and close columns


plt.scatter(df['High'], df['Close'])
corr = df['High'].corr(df['Close'])
plt.title(f'Scatter Plot of High vs Low (Correlation: {corr:4f})')
plt.xlabel('High')
plt.ylabel('Close')

#
#scatter plot between low and close columns
plt.scatter(df['Low'], df['Close'])
corr = df['Low'].corr(df['Close'])
plt.title(f'Scatter Plot of low vs Close (Correlation: {corr:4f})')
plt.xlabel('low')
plt.ylabel('Close')

"""all independent variables are linearly dependent on target variable


Linear Dependence: A clear linear relationship was identified between the Open, High, and Low prices with the Close price. This suggests that the closing price can be predicted with reasonable accuracy using these variables.


Multicollinearity Consideration: Given the inherent relationship between Open, High, and Low prices, there was potential for multicollinearity. To address this, Principal Component Analysis (PCA) was applied to reduce dimensionality and mitigate any multicollinearity issues, ensuring that the regression model remains robust and interpretable.
"""

#Heatmap of OHLC variables

heat_map_data = df[['Open', 'High', 'Low', 'Close']]





sns.heatmap(heat_map_data.corr(), annot=True, cmap='coolwarm')

"""When the OHLC (Open, High, Low, Close) stock prices have a high correlation with each other, it introduces several potential problems in a linear regression model. Specifically, this situation can lead to multicollinearity, which can distort the results and reduce the effectiveness of the regression analysis.

Given the strong linear relationships between the Open, High, and Low prices, there is a risk of multicollinearity—a situation where these variables are highly correlated with each other, which can inflate the variance of coefficient estimates in regression models and reduce their interpretability
"""

#code to visualise scatter plot pairs between each 'ohlc' variables

sns.pairplot(df.drop(columns={'ma_3', 'ma_6'}),diag_kind="kde")

#line plot to visualize time series data of OHLC variables



fig , ax = plt.subplots(2 , 2 ,figsize=(10, 6))


ax = ax.flatten()


sns.lineplot(data=df, x='Date', y='Open', ax=ax[0], label='Open', color='blue')
sns.lineplot(data=df, x='Date', y='High', ax=ax[1], label='High', color='green')
sns.lineplot(data=df, x='Date', y='Low', ax=ax[2], label='Low', color='red')
sns.lineplot(data=df, x='Date', y='Close', ax=ax[3], label='Close', color='orange')

plt.subplots_adjust(hspace=0.5)

plt.xlabel('Date')

plt.legend()
plt.show()

#volatility or rolling 20 days standard deviation graph


df['Volatility'] = df['Close'].rolling(window=20).std()
plt.plot(df['Date'], df['Volatility'], color='purple')
plt.xlabel('Date')
plt.ylabel('Volatility (20-Day Rolling Std Dev)')
plt.title('Volatility of Close Price Over Time')
plt.show()

"""Purpose: To measure the volatility of the close price over time.


: High volatility can indicate periods of increased uncertainty in the stock price.

---

Linear regression assumes that the residuals (the differences between observed and predicted values) are normally distributed. If your features are heavily skewed, it can lead to non-normally distributed residuals, which violates this assumption

to mitigate the effects of skewness, you can apply various transformations to your features

Log Transformation: Often used for right-skewed data. It compresses the range of the data and can help stabilize variance.


X
′
 =log(X+c)
where
𝑐
c is a constant added to avoid taking the logarithm of zero.
"""

#code to log transform data into normal distribution from positively skewed distribution

df['log_open'] = np.log(df['Open'])
df['log_high'] = np.log(df['High'])
df['log_low'] = np.log(df['Low'])
df['log_close'] = np.log(df['Close'])

#code to plot log_open
plt.figure(figsize = (8,5))
sns.histplot(df['log_open'] , kde=True)

#code to plot log_high

plt.figure(figsize = (8,5))
sns.histplot(df['log_high'] , kde=True)

#code to plot log_low

plt.figure(figsize = (8,5))
sns.histplot(df['log_low'] , kde=True)

"""Normalization: The log transformation effectively normalizes the distribution of the OHLC variables, especially if they were previously skewed. This makes them more suitable for modeling.

you can see that in visualised Graph of open vs log_open . 'open'column's distribution looks right skewed but for 'log_open' column's graph is symmetric in nature meaning more towards normal

---

##Hypothetical Statement 1

: The average close price on days when the open price is higher than the previous day's close is greater than on days when it is lower.


Null Hypothesis (H₀): The average close price is the same regardless of whether the open price is higher or lower than the previous day's close.


Alternative Hypothesis (H₁): The average close price is higher when the open price is greater than the previous day's close.
To test this, you can create two groups: one where the open price is higher than the previous day's close, and another where it's lower. Then, perform an independent t-test.
"""

import pandas as pd
from scipy import stats

# Create a new column for the previous day's close price
df['Prev_Close'] = df['Close'].shift(1)

# Create two groups based on the condition
group_higher = df[df['Open'] > df['Prev_Close']]['Close']
group_lower = df[df['Open'] <= df['Prev_Close']]['Close']



# Perform an independent t-test
t_stat, p_value = stats.ttest_ind(group_higher, group_lower, equal_var=False)  # Use equal_var=False if variances are not equal

# Print results
print(f'T-statistic: {t_stat}')
print(f'P-value: {p_value}')

# Set significance level
alpha = 0.05

# Check if we can reject the null hypothesis
if p_value < alpha:
    print("Reject the null hypothesis:")
    print("The average close price is higher when the open price is greater than the previous day's close.")
else:
    print("Fail to reject the null hypothesis:")
    print("The average close price is the same regardless of whether the open price is higher or lower than the previous day's close.")

"""---

##Statement 2

: The Average Closing Price is Higher on Days with Higher High Prices

Null Hypothesis (H0): The average closing price on days with highr high prices is equal to that on days with lower high prices.


Alternative Hypothesis (H1): The average closing price on days with higher high prices is greater than that on days with lower high prices.
Testing Method: Perform a t-test to compare the means of closing prices on days with high prices above a certain threshold and those below.
"""

# Define a threshold for high prices
high_price_threshold = df['High'].mean()

# Split the data based on the threshold
high_close_prices = df[df['High'] > high_price_threshold]['Close']
low_close_prices = df[df['High'] <= high_price_threshold]['Close']

# Perform a t-test
t_stat, p_value = stats.ttest_ind(high_close_prices, low_close_prices)

print(f"T-statistic: {t_stat}")
print(f"P-value: {p_value}")

# Significance level
if p_value < alpha:
    print("Reject the null hypothesis: The average closing price is higher on days with higher high prices.")
else:
    print("Fail to reject the null hypothesis: The average closing price is not significantly higher.")



#code for scaling data variables

scaler = StandardScaler()


data = df[['log_open', 'log_high', 'log_low' ,'log_close']]

scaled_data = scaler.fit_transform(data)   #scaling code

scaled_y = scaled_data[:,3]  #scaled target variable

for i in range(scaled_data.shape[1]-1):  # Loop through each feature to get histplot of features
    plt.figure()
    plt.hist(scaled_data[:, i], bins=30, alpha=0.7, color='blue')
    plt.title(f'Distribution of Feature {i+1}')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.show()

"""Many regression algorithms, such as linear regression using gradient descent, can converge faster when features are on a similar scale. If one feature has a much larger range than others, the optimization algorithm may take longer to converge or may not converge at all.

---

Lets take a look at covariance of columns. covariance matrix, which will show how each pair of features varies together. The values can indicate positive, negative, or no correlation between the features.
"""

cov_matrix = np.cov(scaled_data, rowvar=False)

# Print the covariance matrix
print("Covariance Matrix:")
print(cov_matrix)

"""The analysis indicates that there is a strong correlation among the features, as evidenced by the high covariance values observed in the covariance matrix

---

To address high covariance among features, we can consider several strategies to reduce multicollinearity and improve  model’s performance

one such strategy is PCA we can use feature selection after pca

PCA transforms the original features into a new set of uncorrelated features called principal components. These components are linear combinations of the original features.
The first few principal components usually capture most of the variance in the data, while the later components capture less.

Instead of selecting original features, you can choose a subset of the principal components that explain a significant amount of variance
"""

pca = PCA(n_components=3)
principal_components = pca.fit_transform(scaled_data)


pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2', 'PC3'])

# Explained variance ratio (to understand how much variance is explained by each PC)
explained_variance = pca.explained_variance_ratio_

# Print results
print("Principal Components:\n", pca_df)
print("Explained Variance Ratio:", explained_variance)

# Plotting the explained variance
plt.figure(figsize=(8, 4))
plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, align='center')
plt.ylabel('Variance Ratio')
plt.xlabel('Principal Component')
plt.title('PCA Explained Variance Ratio')
plt.xticks(range(1, len(explained_variance) + 1))
plt.show()

"""In this case, retaining one component (the first one) would suffice to represent the majority of the information in  data. as explained variance is very large in case of first feature and other feature contribute very little"""

transformed_data = pca.transform(scaled_data)[:, 1].reshape(-1, 1)
transformed_data

X_train_log, X_test_log, y_train_log, y_test_log, train_indices, test_indices = train_test_split(pca_df, scaled_y,np.arange(len(scaled_y)), test_size=0.2, random_state=42)

# Get indices of y_train and y_test
print("Train indices:", train_indices)

# Get indices of y_train and y_test
print("Test indices:", test_indices)

"""##Linear Regression Model"""



from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train_log, y_train_log)  # Fit model to PCA-transformed features and log-transformed target

import numpy as np

y_testpred_log = model.predict(X_test_log)
y_testpred = np.exp(y_testpred_log)  # Inverse of the log transformation
y_test_original = np.exp(y_test_log)  # Inverse of the log transformation

from sklearn.metrics import mean_squared_error
import numpy as np

# Assuming y_test contains the true values of the target (log-transformed)
# and y_pred_log contains the predicted log-transformed values from your model.
y_train_pred = np.exp(model.predict(X_train_log))  # Predictions on the original scale
y_train_original = np.exp(y_train_log)  # True values on the original scale (if y_test is log-transformed
y_train_pred_log = model.predict(X_train_log)



# Calculate MSE on the original scale
mse = mean_squared_error(y_test_original, y_testpred)
print(f"Mean Squared Error: {mse}")
np.var(y_test_original)

from sklearn.metrics import mean_squared_error
import numpy as np


# Calculate MSE
mse = mean_squared_error(y_test_original, y_testpred)

# Calculate RMSE
rmse = np.sqrt(mse)
print(f"Root Mean Squared Error: {rmse}")
print(np.mean(y_test_original))

from sklearn.metrics import r2_score
import numpy as np


# Calculate R² score
r2 = r2_score(y_test_original, y_testpred)
print(f"R² Score: {r2}")



"""#### Chart - 10"""

final_test_df = df.iloc[test_indices]
final_test_df

finaltrain_df = df.iloc[train_indices]
finaltrain_df

import numpy as np
import matplotlib.pyplot as plt

# Create a time period index for plotting
# Replace 'time_period' with your actual time index


# Plotting
plt.figure(figsize=(12, 6))
plt.scatter(final_test_df['Date'], y_test_original, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.scatter(final_test_df['Date'], y_testpred, label='Predicted Values', color='orange', marker='x', linestyle='--')

# Adding labels and title
plt.xlabel('Time Period')  # Change as needed (e.g., 'Date' or 'Month')
plt.ylabel('Target Variable')  # Change to your target variable's name
plt.title('Actual vs. Predicted Values Over Time(test data)')
plt.legend()
plt.grid()
plt.show()

import numpy as np
import matplotlib.pyplot as plt


y_train_pred = np.exp(model.predict(X_train_log))  # Predictions on the original scale

# Plotting
plt.figure(figsize=(12, 6))
plt.scatter(finaltrain_df['Date'], y_train_original, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.scatter(finaltrain_df['Date'], y_train_pred, label='Predicted Values', color='orange', marker='x', linestyle='--')

# Adding labels and title
plt.xlabel('Time Period')
plt.ylabel('Target Variable')
plt.title('Actual vs. Predicted Values Over Time  (train Data)')
plt.legend()
plt.grid()
plt.show()



import pandas as pd
import matplotlib.pyplot as plt

# Create a DataFrame that includes Date and y_train_original
combined_df = pd.DataFrame({
    'Date': finaltrain_df['Date'],
    'y_train_original': y_train_original,
    'y_train_pred': y_train_pred
})

# Sort the DataFrame by Date
combined_df_sorted = combined_df.sort_values(by='Date')

# Extract sorted values for plotting
dates_sorted = combined_df_sorted['Date']
y_train_original_sorted = combined_df_sorted['y_train_original']
y_train_pred_sorted = combined_df_sorted['y_train_pred']

# Create a line plot for Actual vs Predicted values sorted by Date
plt.figure(figsize=(10, 6))
plt.plot(dates_sorted, y_train_original_sorted, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.plot(dates_sorted, y_train_pred_sorted, label='Predicted Values', color='orange', marker='x', linestyle='--')

# Add labels and title
plt.xlabel('Date')
plt.ylabel('Target Value')
plt.title('Actual vs Predicted Values Sorted by Date')
plt.legend()
plt.grid(True)

# Show plot
plt.show()





"""##Ridge Regression Model"""

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)

# Fit the model
ridge.fit(X_train_log, y_train_log)

# Predict on test set
y_testpred_ridge = ridge.predict(X_test_log)


import numpy as np

y_testpred_log_ridge = ridge.predict(X_test_log)
y_testpred_ridge = np.exp(y_testpred_log_ridge)  # Inverse of the log transformation
y_test_original = np.exp(y_test_log)  # Inverse of the log transformation


y_train_pred_ridge = np.exp(ridge.predict(X_train_log))  # Predictions on the original scale
y_train_original = np.exp(y_train_log)  # True values on the original scale (if y_test is log-transformed
y_train_pred_log_ridge = ridge.predict(X_train_log)




# Model evaluation
mse = mean_squared_error(y_test_original, y_testpred_ridge)
r2 = r2_score(y_test_original, y_testpred_ridge)
print(f"Ridge MSE: {mse}, R^2: {r2}")

final_test_df_ridge = df.iloc[test_indices]
final_test_df_ridge

finaltrain_df_ridge = df.iloc[train_indices]
finaltrain_df_ridge

import numpy as np
import matplotlib.pyplot as plt



# Plotting
plt.figure(figsize=(12, 6))
plt.scatter(final_test_df_ridge['Date'], y_test_original, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.scatter(final_test_df_ridge['Date'], y_testpred_ridge, label='Predicted Values', color='orange', marker='x', linestyle='--')

# Adding labels and title
plt.xlabel('Time Period')
plt.ylabel('Target Variable')
plt.title('Actual vs. Predicted Values Over Time(test data)')
plt.legend()
plt.grid()
plt.show()

import numpy as np
import matplotlib.pyplot as plt


# Plotting
plt.figure(figsize=(12, 6))
plt.scatter(finaltrain_df_ridge['Date'], y_train_original, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.scatter(finaltrain_df_ridge['Date'], y_train_pred_ridge, label='Predicted Values', color='orange', marker='x', linestyle='--')

# Adding labels and title
plt.xlabel('Time Period')
plt.ylabel('Target Variable')
plt.title('Actual vs. Predicted Values Over Time(train data)')
plt.legend()
plt.grid()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Create a DataFrame that includes Date and y_train_original
combined_df_ridge = pd.DataFrame({
    'Date': finaltrain_df['Date'],
    'y_train_original': y_train_original,
    'y_train_pred': y_train_pred_ridge
})

# Sort the DataFrame by Date
combined_df_ridge_sorted = combined_df_ridge.sort_values(by='Date')

# Extract sorted values for plotting
dates_sorted = combined_df_ridge_sorted['Date']
y_train_original_ridge_sorted = combined_df_ridge_sorted['y_train_original']
y_train_pred_ridge_sorted = combined_df_ridge_sorted['y_train_pred']

# Create a line plot for Actual vs Predicted values sorted by Date
plt.figure(figsize=(10, 6))
plt.plot(dates_sorted, y_train_original_ridge_sorted, label='Actual Values', color='blue', marker='o', linestyle='-')
plt.plot(dates_sorted, y_train_pred_ridge_sorted, label='ridge Predicted Values', color='orange', marker='x', linestyle='--')

# Add labels and title
plt.xlabel('Date')
plt.ylabel('Target Value')
plt.title('Actual vs ridge Predicted Values Sorted by Date')
plt.legend()
plt.grid(True)

# Show plot
plt.show()

"""### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"""